# Calculate accuracy for the second model
acc2 <- accuracy(arima.f2, test_ts)
# Calculate accuracy for the third model
acc3 <- accuracy(arima.f3, test_ts)
# Calculate accuracy for the first model
acc1 <- accuracy(arima.f1, test_ts)
# Calculate accuracy for the second model
acc2 <- accuracy(arima.f2, test_ts)
# Calculate accuracy for the third model
acc3 <- accuracy(arima.f3, test_ts)
print(acc1, acc2, acc3)
# Calculate accuracy for the first model
acc1 <- accuracy(arima.f1, test_ts)
# Calculate accuracy for the second model
acc2 <- accuracy(arima.f2, test_ts)
# Calculate accuracy for the third model
acc3 <- accuracy(arima.f3, test_ts)
rmse_values <- data.frame(Model = c("ARIMA(0,0,0)(0,1,1)[7]", "ARIMA(1,0,0)(0,1,1)[7]", "ARIMA(0,0,1)(0,1,1)[7]"),
RMSE = c(acc1, acc2, acc3))
rmse_values
acc1
acc1[1]
acc1[3]
acc1[3:4]
# Calculate accuracy for the first model
accuracy(arima.f1, test_ts)
# Calculate accuracy for the second model
accuracy(arima.f2, test_ts)
# Calculate accuracy for the third model
accuracy(arima.f3, test_ts)
# Devolping models for the top three models from the auto.arima() function
#ARIMA(0,0,0)(0,1,1)[7]
arima.m1 <- Arima(train_ts, order =c(0,0,0),
seasonal = c(0,1,1),  period = 7, include.drift = TRUE)
# Splitting the dataset
train_data <- final[final$date <= as.Date('2015/05/20'),]
test_data <- final[final$date > as.Date('2015/05/20'),]
# Time series
train_ts <- ts(train_data[,2], frequency=7, start=c(05,03))
test_ts <- ts(test_data[,2], frequency=7, start=c(16,03))
final_ts <- ts(final[,2], frequency=7, start=c(05,03))
best_arima.m3 <- Arima(final_ts, order=c(0,0,1), seasonal = c(0,1,1))
best_arima.m3 <- Arima(final_ts, order=c(0,0,1), seasonal = c(0,1,1))
best_arima.m3.f <- forecast(best_arima.m3, h=14)
plot(best_arima.m3.f, main="ARIMA forecast for the next 14 days", xlab='Date',
ylab='Lettuce demand (ounces)')
best_arima.m3 <- Arima(final_ts, order=c(0,0,1), seasonal = c(0,1,1))
best_arima.m3.f <- forecast(best_arima.m3, h=14)
plot(best_arima.m3.f, main="ARIMA forecast for the next 14 days", xlab='Date',
ylab='Lettuce demand (ounces)') + legend("topright", legend("Actual", "Forecast"))
best_arima.m3 <- Arima(final_ts, order=c(0,0,1), seasonal = c(0,1,1))
best_arima.m3.f <- forecast(best_arima.m3, h=14)
plot(best_arima.m3.f, main="ARIMA forecast for the next 14 days", xlab='Date',
ylab='Lettuce demand (ounces)') + legend("topright", legend("Actual", "Forecast"))
best_arima.m3 <- Arima(final_ts, order=c(0,0,1), seasonal = c(0,1,1))
best_arima.m3.f <- forecast(best_arima.m3, h=14)
plot(best_arima.m3.f, main="ARIMA forecast for the next 14 days", xlab='Date',
ylab='Lettuce demand (ounces)') +
legend("topright", legend("Actual", "Forecast"), box.lty = 0, lty=1, cx=0.5)
# Applying the auto.arima function
auto.arima(train_ts, trace = TRUE, ic = 'bic', allowdrift = FALSE)
# Devolping models for the top three models from the auto.arima() function
#ARIMA(0,0,0)(0,1,1)[7]
arima.m1 <- Arima(train_ts, order =c(0,0,0),
seasonal = c(0,1,1), include.drift = TRUE)
#ARIMA(1,0,0)(0,1,1)[7]
arima.m2 <- Arima(train_ts, order =c(1,0,0),
seasonal = c(0,1,1), include.drift = TRUE)
#ARIMA(0,0,0)(1,1,1)[7]
arima.m3 <- Arima(train_ts, order =c(0,0,1),
seasonal = c(0,1,1), include.drift = TRUE)
# Devolping models for the top three models from the auto.arima() function
# Forecast for ARIMA(0,0,0)(0,1,1)[7]
arima.f1 <- forecast(arima.m1, h=26)
#Forecast for ARIMA(1,0,0)(0,1,1)[7]
arima.f2 <- forecast(arima.m2, h=26)
#Forecast for ARIMA(0,0,1)(0,1,1)[7]
arima.f3 <- forecast(arima.m3, h=26)
# Calculate accuracy for the first model
accuracy(arima.f1, test_ts)
# Calculate accuracy for the second model
accuracy(arima.f2, test_ts)
# Calculate accuracy for the third model
accuracy(arima.f3, test_ts)
best_arima.m3 <- Arima(final_ts, order=c(0,0,0), seasonal = c(1,1,1))
best_arima.m3.f <- forecast(best_arima.m3, h=14)
plot(best_arima.m3.f, main="ARIMA forecast for the next 14 days", xlab='Date',
ylab='Lettuce demand (ounces)') +
legend("topright", legend("Actual", "Forecast"), box.lty = 0, lty=1, cx=0.5)
best_arima.m3 <- Arima(final_ts, order=c(0,0,0), seasonal = c(1,1,1))
best_arima.m3.f <- forecast(best_arima.m3, h=14)
plot(best_arima.m3.f, main="ARIMA forecast for the next 14 days", xlab='Date',
ylab='Lettuce demand (ounces)')
legend("topright", legend("Actual", "Forecast"), box.lty = 0, lty=1, cx=0.5)
best_arima.m3 <- Arima(final_ts, order=c(0,0,0), seasonal = c(1,1,1))
best_arima.m3.f <- forecast(best_arima.m3, h=14)
plot(best_arima.m3.f, main="ARIMA forecast for the next 14 days", xlab='Date',
ylab='Lettuce demand (ounces)',
legend("topright", legend("Actual", "Forecast"), box.lty = 0, lty=1, cx=0.5))
best_arima.m3 <- Arima(final_ts, order=c(0,0,0), seasonal = c(1,1,1))
best_arima.m3.f <- forecast(best_arima.m3, h=14)
plot(best_arima.m3.f, main="ARIMA forecast for the next 14 days", xlab='Date',
ylab='Lettuce demand (ounces)')+
legend("topright", legend("Actual", "Forecast"), box.lty = 0, lty=1, cx=0.5)
best_arima.m3 <- Arima(final_ts, order=c(0,0,0), seasonal = c(1,1,1))
best_arima.m3.f <- forecast(best_arima.m3, h=14)
plot(best_arima.m3.f, main="ARIMA forecast for the next 14 days", xlab='Date',
ylab='Lettuce demand (ounces)')+
legend("topright", legend("Actual", "Forecast"), box.lty = 0, lty=1)
best_arima.m3 <- Arima(final_ts, order=c(0,0,0), seasonal = c(1,1,1))
best_arima.m3.f <- forecast(best_arima.m3, h=14)
plot(best_arima.m3.f, main="ARIMA forecast for the next 14 days", xlab='Date',
ylab='Lettuce demand (ounces)')
best_arima.m3 <- Arima(final_ts, order=c(0,0,0), seasonal = c(1,1,1))
best_arima.m3.f <- forecast(best_arima.m3, h=14)
plot(best_arima.m3.f, main="ARIMA forecast for the next 14 days", xlab='Date',
ylab='Lettuce demand (ounces)')
best_arima.m3 <- Arima(final_ts, order=c(0,0,0), seasonal = c(1,1,1))
best_arima.m3.f <- forecast(best_arima.m3, h=14)
plot(best_arima.m3.f, main="ARIMA forecast for the next 14 days", xlab='Date',
ylab='Lettuce demand (ounces)')
checkresiduals(best_arima.m3)
best_arima.m3 <- Arima(final_ts, order=c(0,0,0), seasonal = c(0,1,1))
best_arima.m3.f <- forecast(best_arima.m3, h=14)
plot(best_arima.m3.f, main="ARIMA forecast for the next 14 days", xlab='Date',
ylab='Lettuce demand (ounces)')
best_arima.m3 <- Arima(final_ts, order=c(0,0,0), seasonal = c(0,1,1))
best_arima.m3.f <- forecast(best_arima.m3, h=14)
plot(best_arima.m3.f, main="ARIMA forecast for the next 14 days", xlab='Date',
ylab='Lettuce demand (ounces)')
checkresiduals(best_arima.m3)
best_arima.m3 <- Arima(final_ts, order=c(0,0,0), seasonal = c(1,1,1))
best_arima.m3.f <- forecast(best_arima.m3, h=14)
plot(best_arima.m3.f, main="ARIMA forecast for the next 14 days", xlab='Date',
ylab='Lettuce demand (ounces)')
checkresiduals(best_arima.m3)
help(checkresiduals)
library(readr)
library(tidyr)
library(dplyr)
library(forecast)
library(ggplot2)
library(tseries)
# Import the main transactional table, which is "menu_items_all"
main <- read_csv('data/menuitem.csv')
# Columns that are necessary
columns <- c("MD5KEY_ORDERSALE", "StoreNumber", "PLU", "Id", "Quantity")
# Keep only necessary columns
main <- main[,columns]
# Filter for store of interest
main <- filter(main, StoreNumber == 46673)
# Import pos_ordersale table
pos_ordersale <- read_csv("data/pos_ordersale.csv")
main <- left_join(main, select(pos_ordersale, c("date", "MD5KEY_ORDERSALE")), by="MD5KEY_ORDERSALE")
# Import pos_ordersale table
menu_items <- read_csv("data/menu_items.csv")
main <- left_join(main, select(menu_items, c("PLU", "MenuItemId", "RecipeId")), by = c("PLU" = "PLU", "Id" = "MenuItemId"))
main
# Import ingredients dataset
ingredients <- read_csv("data/ingredients.csv")
# Grab lettuce's id
filter(ingredients, grepl("Lettuce", IngredientName, ignore.case = TRUE))
# Importing recipes dataset
recipes <- read_csv("data/recipes.csv")
# Importing recipe_ingredients
recipe_ingredient_assignments <- read_csv("data/recipe_ingredient_assignments.csv")
# Filter only for lettuce
recipe_ingredient_assignments <- filter(recipe_ingredient_assignments,
IngredientId == 27)
# Join in the recipe table
recipes <- left_join(recipes, select(recipe_ingredient_assignments,
c("RecipeId", "Quantity")),
by="RecipeId") %>%
# Mutate to change the NA's to 0
mutate(Quantity = ifelse(is.na(Quantity), 0, Quantity)) %>%
#Change the name of the column to specify it comes from direct
rename(quantity_from_direct = Quantity)
# Import sub recipe assignment dataset
recipe_sub_recipe_assignments <- read_csv("data/recipe_sub_recipe_assignments.csv")
# Import the sub_recipes ingredients assignment
sub_recipe_ingr_assignments <- read_csv("data/sub_recipe_ingr_assignments.csv")
# Join the sub_recipes with ingredients to get the recipe id
recipe_sub_recipe_joint <- left_join(sub_recipe_ingr_assignments,
recipe_sub_recipe_assignments,
by='SubRecipeId')
# Filter for lettuce
recipe_sub_recipe_joint <- filter(recipe_sub_recipe_joint,
IngredientId == 27) %>%
mutate(total_quantity = Factor*Quantity)
# Group by recipe
recipe_sub_recipe_joint <- recipe_sub_recipe_joint %>%
group_by(RecipeId) %>%
summarise(total_quantity = sum(total_quantity, na.rm = TRUE))
# Join with the recipes table
recipes_final <- left_join(recipes, recipe_sub_recipe_joint, by="RecipeId") %>%
# Mutate to change the NA's to 0
mutate(total_quantity = ifelse(is.na(total_quantity),
0, total_quantity)) %>%
#Change the name of the column to specify it comes from direct
rename(quantity_from_sub = total_quantity) %>%
#Sum the two columns to get the total of lettuce
mutate(total_lettuce = quantity_from_direct + quantity_from_sub) %>%
#Filter out recipes that do not have lettuce
filter(total_lettuce > 0)
# Join the main transactional table with recipes to get the final table
final <- left_join(main, select(recipes_final,
c("RecipeId", "total_lettuce")),
by="RecipeId") %>%
# Filter out NA's
filter(!is.na(total_lettuce)) %>%
# Multiply by total quantity
mutate(total_lettuce = Quantity*total_lettuce) %>%
# Group by date
group_by(date) %>%
summarise(total_lettuce = sum(total_lettuce))
final
# Transforming date field from the final table
final$date<- as.Date(paste0("20", substr(final$date, 1, 2), "-", substr(final$date, 4, 5), "-", substr(final$date, 7, 8)))
# Build time series
ts <- ts(final, start = min(final$date), frequency = 7)
# Plot the time series directly using ggplot2
ggplot(final, aes(date, total_lettuce)) +
geom_line() +
labs(title = "Time Series Plot of Lettuce Sales",
x = "Date",
y = "Total Lettuce Sales")
library(scales)
# Plot the time series directly using ggplot2
ggplot(final, aes(date, total_lettuce)) +
geom_line() +
labs(title = "Time Series Plot of Lettuce Sales",
x = "Date",
y = "Total Lettuce Sales") +
scale_x_date(labels = date_format("%d-%b"), breaks = date_breaks("7 day")) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
# Transform our df into a time-series object
ar_ts <- ts(final[, 2], frequency=7, start = c(5,3))
# Plot the decomposition of the time-series
stl_result <- decompose(ar_ts)
# Plotting stl
autoplot(stl_result) +
labs(title = "STL Decomposition of Time Series",
x = "Date",
y = "Total Lettuce Sales")
# Splitting the dataset
train_data <- final[final$date <= as.Date('2015/05/20'),]
test_data <- final[final$date > as.Date('2015/05/20'),]
# Time series
train_ts <- ts(train_data[,2], frequency=7, start=c(05,03))
test_ts <- ts(test_data[,2], frequency=7, start=c(16,03))
final_ts <- ts(final[,2], frequency=7, start=c(05,03))
# Plotting the split time series, where the blue line represents the test set
autoplot(train_ts, series="Training") +
autolayer(test_ts, series="Test") +
guides(colour=guide_legend("Split")) +
scale_color_manual(values=c("blue", "black")) +
xlab("Date") +
ylab("Lettuce consumption") +
ggtitle("Train/Test Split: Weekly Data")
# Applying KPSS test
kpss.test(train_ts)
# Applying KPSS test
nsdiffs(train_ts)
# Applying KPSS test
ggtsdisplay(train_ts,
plot.type='partial',
main = 'ACF and PACF',
smooth=TRUE)
# Applying the auto.arima function
auto.arima(train_ts, trace = TRUE, ic = 'bic', allowdrift = FALSE)
# Devolping models for the top three models from the auto.arima() function
#ARIMA(0,0,0)(0,1,1)[7]
arima.m1 <- Arima(train_ts, order =c(0,0,0),
seasonal = c(0,1,1), include.drift = FALSE)
#ARIMA(1,0,0)(0,1,1)[7]
arima.m2 <- Arima(train_ts, order =c(1,0,0),
seasonal = c(0,1,1), include.drift = FALSE)
#ARIMA(0,0,0)(1,1,1)[7]
arima.m3 <- Arima(train_ts, order =c(0,0,1),
seasonal = c(0,1,1), include.drift = FALSE)
# Devolping models for the top three models from the auto.arima() function
# Forecast for ARIMA(0,0,0)(0,1,1)[7]
arima.f1 <- forecast(arima.m1, h=26)
#Forecast for ARIMA(1,0,0)(0,1,1)[7]
arima.f2 <- forecast(arima.m2, h=26)
#Forecast for ARIMA(0,0,1)(0,1,1)[7]
arima.f3 <- forecast(arima.m3, h=26)
# Calculate accuracy for the first model
accuracy(arima.f1, test_ts)
# Calculate accuracy for the second model
accuracy(arima.f2, test_ts)
# Calculate accuracy for the third model
accuracy(arima.f3, test_ts)
best_arima.m3 <- Arima(final_ts, order=c(0,0,0), seasonal = c(1,1,1))
best_arima.m3.f <- forecast(best_arima.m3, h=14)
plot(best_arima.m3.f, main="ARIMA forecast for the next 14 days", xlab='Date',
ylab='Lettuce demand (ounces)')
checkresiduals(best_arima.m3)
# Plotting stl
autoplot(stl_result) +
labs(title = "STL Decomposition of Time Series",
x = "Date",
y = "Total Lettuce Sales")
# Fitting the Holt-winters model to the training set
train_ts.ets1 <- ets(train_ts, model = "ZZZ")
# Print the results
train_ts.ets1
# Train model on the entire data set
final.ets <-  ets(final_ts, model = "ANA")
# Forecast the demand for the next 14 days
final.ets.f <- forecast(final.ets, h=14)
# Plot the forecast
plot(final.ets.f , main="Holt-Winters forecast for the next 14 days", xlab='Date',
ylab='Lettuce demand (ounces)')
print(final.ets)
# Forecast the test set
hw.f1 <- forecast(train_ts.ets1,h=26)
# Determine accuracy against the test set
acc_4 <- accuracy(hw.f1, test_ts)
# Print accuracy
acc_4
final_forecast <- data.frame(best_arima.m3.f$mean)
write.csv(final_forecast, "final_forecast.csv")
checkresiduals(train_ts.ets1)
checkresiduals(train_ts.ets1)
library(readr)
library(tidyr)
library(dplyr)
library(forecast)
library(ggplot2)
library(tseries)
# Import the main transactional table, which is "menu_items_all"
main <- read_csv('data/menuitem.csv')
# Columns that are necessary
columns <- c("MD5KEY_ORDERSALE", "StoreNumber", "PLU", "Id", "Quantity")
# Keep only necessary columns
main <- main[,columns]
# Filter for store of interest
main <- filter(main, StoreNumber == 46673)
# Import pos_ordersale table
pos_ordersale <- read_csv("data/pos_ordersale.csv")
main <- left_join(main, select(pos_ordersale, c("date", "MD5KEY_ORDERSALE")), by="MD5KEY_ORDERSALE")
# Import pos_ordersale table
menu_items <- read_csv("data/menu_items.csv")
main <- left_join(main, select(menu_items, c("PLU", "MenuItemId", "RecipeId")), by = c("PLU" = "PLU", "Id" = "MenuItemId"))
main
# Import ingredients dataset
ingredients <- read_csv("data/ingredients.csv")
# Grab lettuce's id
filter(ingredients, grepl("Lettuce", IngredientName, ignore.case = TRUE))
# Importing recipes dataset
recipes <- read_csv("data/recipes.csv")
# Importing recipe_ingredients
recipe_ingredient_assignments <- read_csv("data/recipe_ingredient_assignments.csv")
# Filter only for lettuce
recipe_ingredient_assignments <- filter(recipe_ingredient_assignments,
IngredientId == 27)
# Join in the recipe table
recipes <- left_join(recipes, select(recipe_ingredient_assignments,
c("RecipeId", "Quantity")),
by="RecipeId") %>%
# Mutate to change the NA's to 0
mutate(Quantity = ifelse(is.na(Quantity), 0, Quantity)) %>%
#Change the name of the column to specify it comes from direct
rename(quantity_from_direct = Quantity)
# Import sub recipe assignment dataset
recipe_sub_recipe_assignments <- read_csv("data/recipe_sub_recipe_assignments.csv")
# Import the sub_recipes ingredients assignment
sub_recipe_ingr_assignments <- read_csv("data/sub_recipe_ingr_assignments.csv")
# Join the sub_recipes with ingredients to get the recipe id
recipe_sub_recipe_joint <- left_join(sub_recipe_ingr_assignments,
recipe_sub_recipe_assignments,
by='SubRecipeId')
# Filter for lettuce
recipe_sub_recipe_joint <- filter(recipe_sub_recipe_joint,
IngredientId == 27) %>%
mutate(total_quantity = Factor*Quantity)
# Group by recipe
recipe_sub_recipe_joint <- recipe_sub_recipe_joint %>%
group_by(RecipeId) %>%
summarise(total_quantity = sum(total_quantity, na.rm = TRUE))
# Join with the recipes table
recipes_final <- left_join(recipes, recipe_sub_recipe_joint, by="RecipeId") %>%
# Mutate to change the NA's to 0
mutate(total_quantity = ifelse(is.na(total_quantity),
0, total_quantity)) %>%
#Change the name of the column to specify it comes from direct
rename(quantity_from_sub = total_quantity) %>%
#Sum the two columns to get the total of lettuce
mutate(total_lettuce = quantity_from_direct + quantity_from_sub) %>%
#Filter out recipes that do not have lettuce
filter(total_lettuce > 0)
# Join the main transactional table with recipes to get the final table
final <- left_join(main, select(recipes_final,
c("RecipeId", "total_lettuce")),
by="RecipeId") %>%
# Filter out NA's
filter(!is.na(total_lettuce)) %>%
# Multiply by total quantity
mutate(total_lettuce = Quantity*total_lettuce) %>%
# Group by date
group_by(date) %>%
summarise(total_lettuce = sum(total_lettuce))
final
# Transforming date field from the final table
final$date<- as.Date(paste0("20", substr(final$date, 1, 2), "-", substr(final$date, 4, 5), "-", substr(final$date, 7, 8)))
# Build time series
ts <- ts(final, start = min(final$date), frequency = 7)
# Plot the time series directly using ggplot2
ggplot(final, aes(date, total_lettuce)) +
geom_line() +
labs(title = "Time Series Plot of Lettuce Sales",
x = "Date",
y = "Total Lettuce Sales")
library(scales)
# Plot the time series directly using ggplot2
ggplot(final, aes(date, total_lettuce)) +
geom_line() +
labs(title = "Time Series Plot of Lettuce Sales",
x = "Date",
y = "Total Lettuce Sales") +
scale_x_date(labels = date_format("%d-%b"), breaks = date_breaks("7 day")) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
# Transform our df into a time-series object
ar_ts <- ts(final[, 2], frequency=7, start = c(5,3))
# Plot the decomposition of the time-series
stl_result <- decompose(ar_ts)
# Plotting stl
autoplot(stl_result) +
labs(title = "STL Decomposition of Time Series",
x = "Date",
y = "Total Lettuce Sales")
# Splitting the dataset
train_data <- final[final$date <= as.Date('2015/05/20'),]
test_data <- final[final$date > as.Date('2015/05/20'),]
# Time series
train_ts <- ts(train_data[,2], frequency=7, start=c(05,03))
test_ts <- ts(test_data[,2], frequency=7, start=c(16,03))
final_ts <- ts(final[,2], frequency=7, start=c(05,03))
# Plotting the split time series, where the blue line represents the test set
autoplot(train_ts, series="Training") +
autolayer(test_ts, series="Test") +
guides(colour=guide_legend("Split")) +
scale_color_manual(values=c("blue", "black")) +
xlab("Date") +
ylab("Lettuce consumption") +
ggtitle("Train/Test Split: Weekly Data")
# Applying KPSS test
kpss.test(train_ts)
# Applying KPSS test
nsdiffs(train_ts)
# Applying KPSS test
ggtsdisplay(train_ts,
plot.type='partial',
main = 'ACF and PACF',
smooth=TRUE)
# Applying the auto.arima function
auto.arima(train_ts, trace = TRUE, ic = 'bic', allowdrift = FALSE)
# Devolping models for the top three models from the auto.arima() function
#ARIMA(0,0,0)(0,1,1)[7]
arima.m1 <- Arima(train_ts, order =c(0,0,0),
seasonal = c(0,1,1), include.drift = FALSE)
#ARIMA(1,0,0)(0,1,1)[7]
arima.m2 <- Arima(train_ts, order =c(1,0,0),
seasonal = c(0,1,1), include.drift = FALSE)
#ARIMA(0,0,0)(1,1,1)[7]
arima.m3 <- Arima(train_ts, order =c(0,0,1),
seasonal = c(0,1,1), include.drift = FALSE)
# Devolping models for the top three models from the auto.arima() function
# Forecast for ARIMA(0,0,0)(0,1,1)[7]
arima.f1 <- forecast(arima.m1, h=26)
#Forecast for ARIMA(1,0,0)(0,1,1)[7]
arima.f2 <- forecast(arima.m2, h=26)
#Forecast for ARIMA(0,0,1)(0,1,1)[7]
arima.f3 <- forecast(arima.m3, h=26)
# Calculate accuracy for the first model
accuracy(arima.f1, test_ts)
# Calculate accuracy for the second model
accuracy(arima.f2, test_ts)
# Calculate accuracy for the third model
accuracy(arima.f3, test_ts)
best_arima.m3 <- Arima(final_ts, order=c(0,0,0), seasonal = c(1,1,1))
best_arima.m3.f <- forecast(best_arima.m3, h=14)
plot(best_arima.m3.f, main="ARIMA forecast for the next 14 days", xlab='Date',
ylab='Lettuce demand (ounces)')
checkresiduals(best_arima.m3)
# Plotting stl
autoplot(stl_result) +
labs(title = "STL Decomposition of Time Series",
x = "Date",
y = "Total Lettuce Sales")
# Fitting the Holt-winters model to the training set
train_ts.ets1 <- ets(train_ts, model = "ZZZ")
# Print the results
train_ts.ets1
checkresiduals(train_ts.ets1)
# Train model on the entire data set
final.ets <-  ets(final_ts, model = "ANA")
# Forecast the demand for the next 14 days
final.ets.f <- forecast(final.ets, h=14)
# Plot the forecast
plot(final.ets.f , main="Holt-Winters forecast for the next 14 days", xlab='Date',
ylab='Lettuce demand (ounces)')
print(final.ets)
# Forecast the test set
hw.f1 <- forecast(train_ts.ets1,h=26)
# Determine accuracy against the test set
acc_4 <- accuracy(hw.f1, test_ts)
# Print accuracy
acc_4
final_forecast <- data.frame(best_arima.m3.f$mean)
write.csv(final_forecast, "final_forecast.csv")
